---
title: "H_D"
author: "Gio Jacuzzi"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Acoustic Entropy/**Dissimilarity Index** (H/D)

#### Sueur et al 2008

If $x(t)$ is a time series of length $n$, the amplitude envelope of oscillation is obtained with the analytic signal $\xi(t)$ of $x(t)$ The analytic signal is defined as:

$$
\xi(t)=x(t)+ix_{H}(t), \text{ where } i^{2}=-1 \text{ and } x_{H}(t) \text{ is the Hilbert transform of } x(t)
$$

The probability mass function of the amplitude envelope $A(t)$ is defined as

$$
A(t)=\frac{|\xi(t)|}{\sum_{t=1}^{n}|\xi(t)|}, \text{ such that } \sum_{t=1}^{n}A(t)=1
$$

In signal theory, the entropy H of a random variable X with probability mass function $p_{X}(x)$ is defined as:

$$
H(X)=-\int_{-\infty}^{+\infty} p_{X}(x)*\text{log}_{2}p_{X}(x)dx
$$

## Acoustic Entropy Index (H)

Shannon index is the second most used index of diversity in ecology, after species richness (number of species) [40]. In general, it is measured on a set of categories differing in frequencies. It increases with the evenness of the frequencies of the categories and with the number of categories. In ecology, categories are often species that differ by their relative abundances in a community. Here we apply it on a time series sequence of size n, the categories are the time units and their frequencies are the probability mass function of the amplitude envelope. The prevalence of Shannon index over other indices especially the Simpson index has a long history of debates [12]. Its main characteristic is that it is more sensitive to rare categories [41]. Therefore by using this index, the time units with low probability mass function of the amplitude envelope will still influence the value of the acoustic diversity. The maximum value of Shannon index depends on the number of categories (log2(n)). The sounds of animals in field will affect the amplitude envelope at each time unit. However the number of time units is fixed by the methodology. Consequently, to obtain an index that is solely affected by the sounds of animals in field, we divide the Shannon index by its maximum. The index obtained measures the evenness of the amplitude envelope over the time units.

The temporal entropy *H~t~* is then computed following

$$
H_{t}=-\sum_{t=1}^{n}A(t)*\text{log}_{2}A(t)*\text{log}_{2}(n)^{-1}, \; \text{with} \; H_{t}\in [0,1]
$$

Similarly, to calculate the spectral entropy, a mean spectrum s(f) is first computed using a Short Time Fourier Transform (STFT) based on a non-overlapping sliding function window of sample width τ. This mean spectrum s(f) is similarly transformed into a probability mass function S(f) of length N used to compute the spectral entropy Hf:

$$
H_{f}=-\sum_{f=1}^{N}S(f)*\text{log}_{2}S(f)*\text{log}_{2}(N)^{-1}, \; \text{with} \; H_{f}\in [0,1]
$$

Eventually, the entropy index *H* is computed as the product of both temporal and spectral entropies:

$$
H=H_{t}*H_{f}, \; \text{with} \; H\in[0,1]
$$

H will tend towards 0 for a single pure tone, increases with the number of frequency bands and amplitude modulations, and tends towards 1 for a random noise. We tested the hypothesis that H index increases with the number of singing species.

The H index, which measures acoustic entropy, shows a logarithmic correlation with the number of species within the acoustic community.

## Acoustic Dissimilarity Index (D)

We extended a measure estimating the compositional dissimilarity between two communities to both envelope and spectral acoustic data. Envelope dissimilarity between two signals $x_{1}(t)$ and $x_{2}(t)$ of the same duration digitized at the same sampling frequency can be estimated by computing the difference between their envelope probability mass functions divided by 2 to get values between 0 and 1:

$$
D_{t}=0.5*\sum_{t=1}^{n}|A_{1}(t)-A_{2}(t)|, \text{ with } D_{t} \in [0,1]
$$

Similarly, spectral dissimilarity can be assed by computing:

$$
D_{f}=0.5*\sum_{t=1}^{N}|S_{1}(f)-S_{2}(f)|, \text{ with } D_{f} \in [0,1]
$$

The dissimilarity acoustic index is computed as the product of both temporal and spectral dissimilarities

$$
D=D_{t}*D_{f}, \text{ with } D \in [0,1]
$$

We tested the hypothesis that *D* index increases with the number of unshared species between chorus pairs.

The β index, which estimates both temporal and spectral dissimilarities, is linearly linked to the number of unshared species between acoustic communities.

#### Bradfer-Lawrence et al 2019

Soundscape patterns (H) - Related to the classic Shannon's Index, were a number of categories each have a relative proportion associated with them. Here the categories are either frequency bands (Hf) or time samples (Ht), and the relative amplitude is the "proportion" in each category. Hf and Ht are multiplied to give the index, returns a value between 0 and 1. H increases with greater evenness of amplitude among frequency bands, (or with an increasing number of bands). An even signal will be closer to 1 (could be noisy across frequency bands or completely silent) and a pure tone (i.e. all energy in one frequency band) will be closer to 0.

Patterns in this study (H) - Highest values come from near-silent recordings, with no wind, and only faint bird calls. Lowest values produced when insect noise dominated a single frequency band.

Principle (Alcocer et al 2022):

-   Ht (Temporal Entropy Index) - Shannon entropy of the amplitude envelope
-   Hf (Spectral Entropy Index) - Shannon entropy of the frequency spectrum
-   H (Acoustic Entropy Index) - Product of Ht and Hf

```{r}
library(soundecology)
library(tuneR)
library(seewave)

# Load test data
path = '~/Desktop/oesf-examples'
files = list.files(path=path, pattern='*.wav', full.names=T, recursive=T)

results = data.frame()
for (file in files) {
  message('Processing file ', basename(file))
  
  wav = readWave(file)
  h = H(wav)
  results = append(results, h)
}
```

### References
